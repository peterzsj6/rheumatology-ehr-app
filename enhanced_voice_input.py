import streamlit as st
import streamlit.components.v1 as components
from streamlit_speech_service import create_streamlit_speech_service
import tempfile
import os
import base64
import json

def enhanced_voice_input_component():
    """å¢å¼ºçš„è¯­éŸ³è¾“å…¥ç»„ä»¶ï¼Œæ”¯æŒè‡ªåŠ¨è½¬æ¢"""
    
    # HTMLå’ŒJavaScriptä»£ç 
    html_code = """
    <div id="enhanced-voice-input-container">
        <button id="start-recording" onclick="startRecording()" style="
            background-color: #007bff; 
            color: white; 
            border: none; 
            padding: 10px 20px; 
            border-radius: 5px; 
            cursor: pointer;
            margin: 5px;
        ">ğŸ¤ å¼€å§‹å½•éŸ³</button>
        
        <button id="stop-recording" onclick="stopRecording()" style="
            background-color: #dc3545; 
            color: white; 
            border: none; 
            padding: 10px 20px; 
            border-radius: 5px; 
            cursor: pointer;
            margin: 5px;
            display: none;
        ">â¹ï¸ åœæ­¢å½•éŸ³</button>
        
        <div id="recording-status" style="
            text-align: center; 
            color: red; 
            font-size: 1.2rem; 
            margin: 10px 0;
            display: none;
        ">âºï¸ å½•éŸ³ä¸­...</div>
        
        <div id="transcription-result" style="
            margin: 10px 0; 
            padding: 10px; 
            background-color: #f8f9fa; 
            border-radius: 5px;
            display: none;
        "></div>
        
        <div id="auto-convert-status" style="
            text-align: center; 
            color: #28a745; 
            font-size: 1rem; 
            margin: 10px 0;
            display: none;
        ">ğŸ”„ æ­£åœ¨è‡ªåŠ¨è½¬æ¢è¯­éŸ³...</div>
    </div>

    <script>
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let recordingStartTime;

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });
            
            // ä½¿ç”¨æ­£ç¡®çš„MIMEç±»å‹
            const mimeType = 'audio/webm;codecs=opus';
            mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });
            audioChunks = [];
            
            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: mimeType });
                
                // æ˜¾ç¤ºå½•éŸ³ç»“æœ
                document.getElementById('transcription-result').innerHTML = 
                    '<strong>å½•éŸ³å®Œæˆï¼</strong><br>' +
                    '<audio controls><source src="' + URL.createObjectURL(audioBlob) + '" type="' + mimeType + '"></audio><br>';
                document.getElementById('transcription-result').style.display = 'block';
                
                // æ˜¾ç¤ºè‡ªåŠ¨è½¬æ¢çŠ¶æ€
                document.getElementById('auto-convert-status').style.display = 'block';
                document.getElementById('auto-convert-status').textContent = 'ğŸ”„ æ­£åœ¨è‡ªåŠ¨è½¬æ¢è¯­éŸ³...';
                
                // è‡ªåŠ¨è½¬æ¢éŸ³é¢‘
                await autoConvertAudio(audioBlob);
            };
            
            mediaRecorder.start();
            isRecording = true;
            recordingStartTime = Date.now();
            
            // æ›´æ–°UI
            document.getElementById('start-recording').style.display = 'none';
            document.getElementById('stop-recording').style.display = 'inline-block';
            document.getElementById('recording-status').style.display = 'block';
            
            // æ›´æ–°å½•éŸ³æ—¶é—´
            updateRecordingTime();
            
        } catch (error) {
            alert('æ— æ³•è®¿é—®éº¦å…‹é£: ' + error.message);
        }
    }
    
    function stopRecording() {
        if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            isRecording = false;
            
            // æ›´æ–°UI
            document.getElementById('start-recording').style.display = 'inline-block';
            document.getElementById('stop-recording').style.display = 'none';
            document.getElementById('recording-status').style.display = 'none';
        }
    }
    
    function updateRecordingTime() {
        if (isRecording) {
            const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
            document.getElementById('recording-status').textContent = `âºï¸ å½•éŸ³ä¸­... ${elapsed}ç§’`;
            setTimeout(updateRecordingTime, 1000);
        }
    }
    
    async function autoConvertAudio(audioBlob) {
        try {
            // å°†éŸ³é¢‘è½¬æ¢ä¸ºbase64
            const arrayBuffer = await audioBlob.arrayBuffer();
            const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
            
            // å‘é€åˆ°Streamlitè¿›è¡Œè½¬æ¢
            const data = {
                audio_data: base64Audio,
                audio_type: audioBlob.type,
                language: 'zh-CN'
            };
            
            // ä½¿ç”¨Streamlitçš„ç»„ä»¶é€šä¿¡
            window.parent.postMessage({
                type: 'AUDIO_CONVERSION_REQUEST',
                data: data
            }, '*');
            
        } catch (error) {
            console.error('éŸ³é¢‘è½¬æ¢å¤±è´¥:', error);
            document.getElementById('auto-convert-status').textContent = 'âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥';
        }
    }
    
    // ç›‘å¬æ¥è‡ªStreamlitçš„æ¶ˆæ¯
    window.addEventListener('message', function(event) {
        if (event.data.type === 'AUDIO_CONVERSION_RESULT') {
            const result = event.data.data;
            if (result.success) {
                document.getElementById('auto-convert-status').textContent = 'âœ… è¯­éŸ³è½¬æ¢å®Œæˆï¼';
                // å¯ä»¥åœ¨è¿™é‡Œæ˜¾ç¤ºè½¬æ¢ç»“æœ
            } else {
                document.getElementById('auto-convert-status').textContent = 'âŒ è¯­éŸ³è½¬æ¢å¤±è´¥: ' + result.error;
            }
        }
    });
    </script>
    """
    
    # æ¸²æŸ“ç»„ä»¶
    components.html(html_code, height=400)

def enhanced_voice_input_section():
    """å¢å¼ºçš„è¯­éŸ³è¾“å…¥åŒºåŸŸ"""
    st.markdown('<h3 class="section-header">ğŸ¤ è¯­éŸ³è¾“å…¥ï¼ˆå¢å¼ºç‰ˆï¼‰</h3>', unsafe_allow_html=True)
    
    # è¯­éŸ³è¾“å…¥è¯´æ˜
    st.info("""
    **å¢å¼ºç‰ˆè¯­éŸ³è¾“å…¥åŠŸèƒ½ï¼š**
    1. ç‚¹å‡»"å¼€å§‹å½•éŸ³"æŒ‰é’®å¼€å§‹å½•éŸ³
    2. è¯´è¯å®Œæˆåç‚¹å‡»"åœæ­¢å½•éŸ³"
    3. ç³»ç»Ÿä¼šè‡ªåŠ¨è½¬æ¢è¯­éŸ³ä¸ºæ–‡å­—
    4. è½¬æ¢ç»“æœä¼šè‡ªåŠ¨å¡«å…¥é—®è¯Šè®°å½•è¾“å…¥æ¡†
    """)
    
    # æ¸²æŸ“å¢å¼ºçš„è¯­éŸ³è¾“å…¥ç»„ä»¶
    enhanced_voice_input_component()
    
    st.markdown("---")
    st.markdown("**æˆ–è€…ç›´æ¥ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼š**")
    
    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_audio = st.file_uploader(
        "ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒWAVã€MP3ã€WebMæ ¼å¼ï¼‰",
        type=['wav', 'mp3', 'webm', 'ogg'],
        key="enhanced_audio_uploader"
    )
    
    if uploaded_audio is not None:
        st.success(f"å·²ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶: {uploaded_audio.name}")
        
        # æ˜¾ç¤ºéŸ³é¢‘æ’­æ”¾å™¨
        st.audio(uploaded_audio, format='audio/wav')
        
        # è¯­éŸ³è¯†åˆ«æœåŠ¡é…ç½®
        st.markdown("**è¯­éŸ³è¯†åˆ«æœåŠ¡é…ç½®ï¼š**")
        col1, col2 = st.columns(2)
        
        with col1:
            service_type = st.selectbox(
                "é€‰æ‹©è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼š",
                ["google", "azure", "baidu", "tencent"],
                format_func=lambda x: {
                    "google": "Google Speech Recognition",
                    "azure": "Azure Speech Services", 
                    "baidu": "ç™¾åº¦è¯­éŸ³è¯†åˆ«",
                    "tencent": "è…¾è®¯è¯­éŸ³è¯†åˆ«"
                }[x],
                key="enhanced_service_type"
            )
        
        with col2:
            language = st.selectbox(
                "é€‰æ‹©è¯­è¨€ï¼š",
                ["zh-CN", "zh-TW", "en-US", "en-GB"],
                format_func=lambda x: {
                    "zh-CN": "ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰",
                    "zh-TW": "ä¸­æ–‡ï¼ˆç¹ä½“ï¼‰", 
                    "en-US": "è‹±è¯­ï¼ˆç¾å›½ï¼‰",
                    "en-GB": "è‹±è¯­ï¼ˆè‹±å›½ï¼‰"
                }[x],
                key="enhanced_language"
            )
        
        # è½¬æ¢æŒ‰é’®
        if st.button("ğŸµ è½¬æ¢è¯­éŸ³ä¸ºæ–‡å­—", key="enhanced_convert_audio"):
            with st.spinner("æ­£åœ¨è½¬æ¢è¯­éŸ³..."):
                try:
                    # åˆ›å»ºè¯­éŸ³è¯†åˆ«æœåŠ¡
                    speech_service = create_streamlit_speech_service(service_type=service_type)
                    
                    # å¤„ç†ä¸åŒæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶
                    audio_data = uploaded_audio.getvalue()
                    file_extension = uploaded_audio.name.split('.')[-1].lower()
                    
                    # æ ¹æ®æ–‡ä»¶æ ¼å¼é€‰æ‹©æ­£ç¡®çš„åç¼€
                    if file_extension in ['mp3', 'webm', 'ogg']:
                        suffix = f".{file_extension}"
                    else:
                        suffix = ".wav"
                    
                    # è½¬æ¢éŸ³é¢‘æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as temp_file:
                        temp_file.write(audio_data)
                        temp_audio_path = temp_file.name
                    
                    # è¿›è¡Œè¯­éŸ³è¯†åˆ«
                    transcribed_text = speech_service.transcribe_audio_file(temp_audio_path, language)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.unlink(temp_audio_path)
                    except:
                        pass
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.transcribed_text = transcribed_text
                    st.success("è¯­éŸ³è½¬æ¢å®Œæˆï¼")
                    
                    # è‡ªåŠ¨å¡«å…¥é—®è¯Šè®°å½•è¾“å…¥æ¡†
                    if "example_text" not in st.session_state:
                        st.session_state.example_text = ""
                    st.session_state.example_text = transcribed_text
                    
                except Exception as e:
                    st.error(f"è¯­éŸ³è½¬æ¢å¤±è´¥: {str(e)}")
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œæä¾›ç¤ºä¾‹æ–‡å­—
                    st.session_state.transcribed_text = "æ‚£è€…ä¸»è¯‰å…³èŠ‚ç–¼ç—›3ä¸ªæœˆï¼Œæ™¨åƒµæ˜æ˜¾ï¼Œä¼´æœ‰çš®ç–¹å’Œå‘çƒ­ç—‡çŠ¶ã€‚"
                    st.info("å·²æä¾›ç¤ºä¾‹æ–‡å­—ï¼Œæ‚¨å¯ä»¥ç¼–è¾‘åä½¿ç”¨ã€‚")
    
    # æ˜¾ç¤ºè½¬æ¢åçš„æ–‡å­—
    if hasattr(st.session_state, 'transcribed_text'):
        st.markdown("### è½¬æ¢ç»“æœï¼š")
        st.text_area("è¯­éŸ³è½¬æ¢æ–‡å­—ï¼š", value=st.session_state.transcribed_text, height=100, key="enhanced_transcribed_text_area")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ä½¿ç”¨æ­¤æ–‡å­—", key="enhanced_use_transcribed_text"):
                st.session_state.example_text = st.session_state.transcribed_text
                st.success("å·²ä½¿ç”¨è½¬æ¢çš„æ–‡å­—ï¼")
        with col2:
            if st.button("ğŸ”„ é‡æ–°è½¬æ¢", key="enhanced_retry_transcription"):
                del st.session_state.transcribed_text
                st.rerun() 