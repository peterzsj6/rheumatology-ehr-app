import streamlit as st
import streamlit.components.v1 as components
from streamlit_speech_service import create_streamlit_speech_service
import tempfile
import os
import base64

def simple_voice_input_component():
    """ç®€åŒ–çš„è¯­éŸ³è¾“å…¥ç»„ä»¶ï¼Œä½¿ç”¨æ›´å¯é çš„é€šä¿¡æœºåˆ¶"""
    
    # HTMLå’ŒJavaScriptä»£ç 
    html_code = """
    <div id="simple-voice-input-container">
        <button id="start-recording" onclick="startRecording()" style="
            background-color: #007bff; 
            color: white; 
            border: none; 
            padding: 10px 20px; 
            border-radius: 5px; 
            cursor: pointer;
            margin: 5px;
        ">ğŸ¤ å¼€å§‹å½•éŸ³</button>
        
        <button id="stop-recording" onclick="stopRecording()" style="
            background-color: #dc3545; 
            color: white; 
            border: none; 
            padding: 10px 20px; 
            border-radius: 5px; 
            cursor: pointer;
            margin: 5px;
            display: none;
        ">â¹ï¸ åœæ­¢å½•éŸ³</button>
        
        <div id="recording-status" style="
            text-align: center; 
            color: red; 
            font-size: 1.2rem; 
            margin: 10px 0;
            display: none;
        ">âºï¸ å½•éŸ³ä¸­...</div>
        
        <div id="recording-result" style="
            margin: 10px 0; 
            padding: 10px; 
            background-color: #f8f9fa; 
            border-radius: 5px;
            display: none;
        "></div>
        
        <div id="conversion-status" style="
            text-align: center; 
            color: #28a745; 
            font-size: 1rem; 
            margin: 10px 0;
            display: none;
        ">ğŸ”„ æ­£åœ¨è½¬æ¢è¯­éŸ³...</div>
    </div>

    <script>
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let recordingStartTime;

    async function startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    sampleRate: 16000,
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });
            
            // ä½¿ç”¨WebMæ ¼å¼ï¼Œæµè§ˆå™¨åŸç”Ÿæ”¯æŒ
            const mimeType = 'audio/webm;codecs=opus';
            mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });
            audioChunks = [];
            
            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: mimeType });
                
                // æ˜¾ç¤ºå½•éŸ³ç»“æœ
                const audioUrl = URL.createObjectURL(audioBlob);
                document.getElementById('recording-result').innerHTML = 
                    '<strong>å½•éŸ³å®Œæˆï¼</strong><br>' +
                    '<audio controls><source src="' + audioUrl + '" type="' + mimeType + '"></audio><br>' +
                    '<button onclick="downloadAudio()" style="background-color: #28a745; color: white; border: none; padding: 8px 16px; border-radius: 4px; margin: 5px;">ğŸ“¥ ä¸‹è½½å½•éŸ³</button>' +
                    '<button onclick="convertAudio()" style="background-color: #007bff; color: white; border: none; padding: 8px 16px; border-radius: 4px; margin: 5px;">ğŸµ è½¬æ¢è¯­éŸ³</button>';
                document.getElementById('recording-result').style.display = 'block';
                
                // ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°å…¨å±€å˜é‡
                window.recordedAudioBlob = audioBlob;
            };
            
            mediaRecorder.start();
            isRecording = true;
            recordingStartTime = Date.now();
            
            // æ›´æ–°UI
            document.getElementById('start-recording').style.display = 'none';
            document.getElementById('stop-recording').style.display = 'inline-block';
            document.getElementById('recording-status').style.display = 'block';
            
            // æ›´æ–°å½•éŸ³æ—¶é—´
            updateRecordingTime();
            
        } catch (error) {
            alert('æ— æ³•è®¿é—®éº¦å…‹é£: ' + error.message);
        }
    }
    
    function stopRecording() {
        if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            isRecording = false;
            
            // æ›´æ–°UI
            document.getElementById('start-recording').style.display = 'inline-block';
            document.getElementById('stop-recording').style.display = 'none';
            document.getElementById('recording-status').style.display = 'none';
        }
    }
    
    function updateRecordingTime() {
        if (isRecording) {
            const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
            document.getElementById('recording-status').textContent = `âºï¸ å½•éŸ³ä¸­... ${elapsed}ç§’`;
            setTimeout(updateRecordingTime, 1000);
        }
    }
    
    function downloadAudio() {
        if (window.recordedAudioBlob) {
            const url = URL.createObjectURL(window.recordedAudioBlob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'recording.webm';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
    }
    
    function convertAudio() {
        if (!window.recordedAudioBlob) {
            alert('æ²¡æœ‰å¯è½¬æ¢çš„å½•éŸ³');
            return;
        }
        
        // æ˜¾ç¤ºè½¬æ¢çŠ¶æ€
        document.getElementById('conversion-status').style.display = 'block';
        document.getElementById('conversion-status').textContent = 'ğŸ”„ æ­£åœ¨è½¬æ¢è¯­éŸ³...';
        
        // æ¨¡æ‹Ÿè½¬æ¢è¿‡ç¨‹ï¼ˆå®é™…è½¬æ¢åœ¨Streamlitåç«¯è¿›è¡Œï¼‰
        setTimeout(() => {
            document.getElementById('conversion-status').textContent = 'âœ… è¯·ä¸Šä¼ å½•éŸ³æ–‡ä»¶è¿›è¡Œè½¬æ¢';
        }, 2000);
    }
    </script>
    """
    
    # æ¸²æŸ“ç»„ä»¶
    components.html(html_code, height=350)

def simple_voice_input_section():
    """ç®€åŒ–çš„è¯­éŸ³è¾“å…¥åŒºåŸŸ"""
    st.markdown('<h3 class="section-header">ğŸ¤ è¯­éŸ³è¾“å…¥ï¼ˆç®€åŒ–ç‰ˆï¼‰</h3>', unsafe_allow_html=True)
    
    # è¯­éŸ³è¾“å…¥è¯´æ˜
    st.info("""
    **ç®€åŒ–ç‰ˆè¯­éŸ³è¾“å…¥åŠŸèƒ½ï¼š**
    1. ç‚¹å‡»"å¼€å§‹å½•éŸ³"æŒ‰é’®å¼€å§‹å½•éŸ³
    2. è¯´è¯å®Œæˆåç‚¹å‡»"åœæ­¢å½•éŸ³"
    3. ä¸‹è½½å½•éŸ³æ–‡ä»¶åä¸Šä¼ è¿›è¡Œè½¬æ¢
    4. æˆ–ç›´æ¥ä½¿ç”¨æ–‡æœ¬è¾“å…¥åŠŸèƒ½
    """)
    
    # æ¸²æŸ“ç®€åŒ–çš„è¯­éŸ³è¾“å…¥ç»„ä»¶
    simple_voice_input_component()
    
    st.markdown("---")
    st.markdown("**ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè½¬æ¢ï¼š**")
    
    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_audio = st.file_uploader(
        "ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒWAVã€MP3ã€WebMæ ¼å¼ï¼‰",
        type=['wav', 'mp3', 'webm', 'ogg'],
        key="simple_audio_uploader"
    )
    
    if uploaded_audio is not None:
        st.success(f"å·²ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶: {uploaded_audio.name}")
        
        # æ˜¾ç¤ºéŸ³é¢‘æ’­æ”¾å™¨
        st.audio(uploaded_audio, format='audio/wav')
        
        # è¯­éŸ³è¯†åˆ«æœåŠ¡é…ç½®
        st.markdown("**è¯­éŸ³è¯†åˆ«æœåŠ¡é…ç½®ï¼š**")
        col1, col2 = st.columns(2)
        
        with col1:
            service_type = st.selectbox(
                "é€‰æ‹©è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼š",
                ["google", "azure", "baidu", "tencent"],
                format_func=lambda x: {
                    "google": "Google Speech Recognition",
                    "azure": "Azure Speech Services", 
                    "baidu": "ç™¾åº¦è¯­éŸ³è¯†åˆ«",
                    "tencent": "è…¾è®¯è¯­éŸ³è¯†åˆ«"
                }[x],
                key="simple_service_type"
            )
        
        with col2:
            language = st.selectbox(
                "é€‰æ‹©è¯­è¨€ï¼š",
                ["zh-CN", "zh-TW", "en-US", "en-GB"],
                format_func=lambda x: {
                    "zh-CN": "ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰",
                    "zh-TW": "ä¸­æ–‡ï¼ˆç¹ä½“ï¼‰", 
                    "en-US": "è‹±è¯­ï¼ˆç¾å›½ï¼‰",
                    "en-GB": "è‹±è¯­ï¼ˆè‹±å›½ï¼‰"
                }[x],
                key="simple_language"
            )
        
        # è½¬æ¢æŒ‰é’®
        if st.button("ğŸµ è½¬æ¢è¯­éŸ³ä¸ºæ–‡å­—", key="simple_convert_audio"):
            with st.spinner("æ­£åœ¨è½¬æ¢è¯­éŸ³..."):
                try:
                    # åˆ›å»ºè¯­éŸ³è¯†åˆ«æœåŠ¡
                    speech_service = create_streamlit_speech_service(service_type=service_type)
                    
                    # å¤„ç†ä¸åŒæ ¼å¼çš„éŸ³é¢‘æ–‡ä»¶
                    audio_data = uploaded_audio.getvalue()
                    file_extension = uploaded_audio.name.split('.')[-1].lower()
                    
                    # æ ¹æ®æ–‡ä»¶æ ¼å¼é€‰æ‹©æ­£ç¡®çš„åç¼€
                    if file_extension in ['mp3', 'webm', 'ogg']:
                        suffix = f".{file_extension}"
                    else:
                        suffix = ".wav"
                    
                    # è½¬æ¢éŸ³é¢‘æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as temp_file:
                        temp_file.write(audio_data)
                        temp_audio_path = temp_file.name
                    
                    # è¿›è¡Œè¯­éŸ³è¯†åˆ«
                    transcribed_text = speech_service.transcribe_audio_file(temp_audio_path, language)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.unlink(temp_audio_path)
                    except:
                        pass
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.transcribed_text = transcribed_text
                    st.success("è¯­éŸ³è½¬æ¢å®Œæˆï¼")
                    
                    # è‡ªåŠ¨å¡«å…¥é—®è¯Šè®°å½•è¾“å…¥æ¡†
                    if "example_text" not in st.session_state:
                        st.session_state.example_text = ""
                    st.session_state.example_text = transcribed_text
                    
                except Exception as e:
                    st.error(f"è¯­éŸ³è½¬æ¢å¤±è´¥: {str(e)}")
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œæä¾›ç¤ºä¾‹æ–‡å­—
                    st.session_state.transcribed_text = "æ‚£è€…ä¸»è¯‰å…³èŠ‚ç–¼ç—›3ä¸ªæœˆï¼Œæ™¨åƒµæ˜æ˜¾ï¼Œä¼´æœ‰çš®ç–¹å’Œå‘çƒ­ç—‡çŠ¶ã€‚"
                    st.info("å·²æä¾›ç¤ºä¾‹æ–‡å­—ï¼Œæ‚¨å¯ä»¥ç¼–è¾‘åä½¿ç”¨ã€‚")
    
    # æ˜¾ç¤ºè½¬æ¢åçš„æ–‡å­—
    if hasattr(st.session_state, 'transcribed_text'):
        st.markdown("### è½¬æ¢ç»“æœï¼š")
        st.text_area("è¯­éŸ³è½¬æ¢æ–‡å­—ï¼š", value=st.session_state.transcribed_text, height=100, key="simple_transcribed_text_area")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ä½¿ç”¨æ­¤æ–‡å­—", key="simple_use_transcribed_text"):
                st.session_state.example_text = st.session_state.transcribed_text
                st.success("å·²ä½¿ç”¨è½¬æ¢çš„æ–‡å­—ï¼")
        with col2:
            if st.button("ğŸ”„ é‡æ–°è½¬æ¢", key="simple_retry_transcription"):
                del st.session_state.transcribed_text
                st.rerun() 